{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from collections import namedtuple\n",
    "from typing import List, NamedTuple, Tuple\n",
    "import subprocess as sp\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataPoint = namedtuple('DataPoint', ['gray', 'depth', 'user', 'skel', 'label'])\n",
    "Coords = namedtuple('Coords', ['x', 'y'])\n",
    "Joints = namedtuple('Joints', ['head', 'neck', 'left', 'right'])\n",
    "Bounds = namedtuple('Bounds', ['min', 'max'])\n",
    "\n",
    "def read_sample(sample_num):\n",
    "    base_dir = \"/media/amey/76D076A5D0766B6F/chalap\"\n",
    "    train_dir = base_dir + \"/train\"\n",
    "\n",
    "    color_path = \"{}/{}/Sample{:04d}.mp4\".format(train_dir, \"color\", sample_num)\n",
    "    depth_path = \"{}/{}/Sample{:04d}.mp4\".format(train_dir, \"depth\", sample_num)\n",
    "    user_path = \"{}/{}/Sample{:04d}.mp4\".format(train_dir, \"user\", sample_num)\n",
    "    labels_path = \"{}/{}/Sample{:04d}.csv\".format(train_dir, \"labels\", sample_num)\n",
    "    skel_path = \"{}/{}/Sample{:04d}.csv\".format(train_dir, \"skel\", sample_num)\n",
    "    \n",
    "    data = []\n",
    "    color_vid = cv2.VideoCapture(color_path)\n",
    "    depth_vid = cv2.VideoCapture(depth_path)\n",
    "    user_vid = cv2.VideoCapture(user_path)\n",
    "    i = 0\n",
    "\n",
    "    with open(labels_path) as labels_file:\n",
    "        with open(skel_path) as skels_file:\n",
    "            for gesture_frames in labels_file:\n",
    "                [label,frame_start,frame_end] = [int(n) for n in gesture_frames.split(',')]\n",
    "                while i < frame_start:\n",
    "                    point = next_data_point(color_vid, depth_vid, user_vid, skels_file, 0)\n",
    "                    if (point is not None):\n",
    "                        data.append(point)\n",
    "                    i += 1\n",
    "                while i <= frame_end:\n",
    "                    point = next_data_point(color_vid, depth_vid, user_vid, skels_file, label)\n",
    "                    if (point is not None):\n",
    "                        data.append(point)\n",
    "                    i += 1\n",
    "                    \n",
    "    return data\n",
    "\n",
    "def read_and_convert(video):\n",
    "    ret, frame = video.read()\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) if ret else None\n",
    "\n",
    "def next_data_point(color_vid, depth_vid, user_vid, skels_file, label):\n",
    "    gray = read_and_convert(color_vid)\n",
    "    depth = read_and_convert(depth_vid)\n",
    "    user = read_and_convert(user_vid)\n",
    "    \n",
    "    if (gray is not None and depth is not None and user is not None):\n",
    "        return DataPoint(gray=gray, depth=depth, user=user,\n",
    "                         skel=get_joint_locs(skels_file.readline().split(',')),\n",
    "                         label=label)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_joint_locs(joints: List[int]):\n",
    "    for i in range(0, len(joints), 9):\n",
    "        if (i // 9) not in [2,3,7,11]:\n",
    "            continue\n",
    "        if (i // 9) == 2:\n",
    "            neckX = int(joints[i+7])\n",
    "            neckY = int(joints[i+8])\n",
    "        if (i // 9) == 3:\n",
    "            headX = int(joints[i+7])\n",
    "            headY = int(joints[i+8])\n",
    "        # X and Y are reversed\n",
    "        elif (i // 9) == 7:\n",
    "            leftX = int(joints[i+7])\n",
    "            leftY = int(joints[i+8])\n",
    "        # X and Y are reversed\n",
    "        elif (i // 9) == 11:\n",
    "            rightX = int(joints[i+7])\n",
    "            rightY = int(joints[i+8])\n",
    "            \n",
    "    return Joints(head=Coords(x=headX, y=headY),\n",
    "                  neck=Coords(x=neckX, y=neckY),\n",
    "                  left=Coords(x=leftX, y=leftY),\n",
    "                  right=Coords(x=rightX, y=rightY))\n",
    "\n",
    "def valid_coords(joint_locs: Joints):\n",
    "    if (joint_locs.head.x == 0 and joint_locs.head.y == 0 and\n",
    "        joint_locs.neck.x == 0 and joint_locs.neck.y == 0 and\n",
    "        joint_locs.left.x == 0 and joint_locs.left.y == 0 and\n",
    "        joint_locs.right.x == 0 and joint_locs.right.y == 0):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def get_hand_bounds(data: List[DataPoint]):\n",
    "    minX, minY, maxX, maxY = 640, 480, 0, 0\n",
    "    for point in data:\n",
    "        if (point.label != 0) and valid_coords(point.skel):\n",
    "            minX = min(minX, point.skel.left.x, point.skel.right.x)\n",
    "            minY = min(minY, point.skel.left.y, point.skel.right.y)\n",
    "            maxX = max(maxX, point.skel.left.x, point.skel.right.x)\n",
    "            maxY = max(maxY, point.skel.left.y, point.skel.right.y)\n",
    "            \n",
    "    if (minX, minY, maxX, maxY) == (640, 480, 0, 0):\n",
    "        minX, minY, maxX, maxY = 0, 0, 640, 480\n",
    "            \n",
    "    return Bounds(min=Coords(x=minX, y=minY), max=Coords(x=maxX, y=maxY))\n",
    "\n",
    "def crop_frame(frame: np.ndarray, bounds: Bounds):\n",
    "    minX, maxX, _, maxY = bounds.min.x, bounds.max.x, bounds.min.y, bounds.max.y\n",
    "    if maxX - minX > maxY:\n",
    "        maxY = maxX - minX\n",
    "    else:\n",
    "        diff = (maxY - (maxX - minX))\n",
    "        minX = max(0, minX - (diff // 2))\n",
    "        maxX = min(640, (maxY + minX))\n",
    "        \n",
    "    return frame[:maxY, minX:maxX]\n",
    "\n",
    "def write_video(frames: List[np.ndarray], name: str):\n",
    "    writer = cv2.VideoWriter(name, cv2.VideoWriter_fourcc(*'H264'), 20.0, (frames[0].shape[1], frames[0].shape[0]))\n",
    "    for frame in frames:\n",
    "        writer.write(cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB))\n",
    "    writer.release()\n",
    "    \n",
    "def write_video_ffmpeg(frames: List[np.ndarray], name: str):\n",
    "    command = [ \"ffmpeg\",\n",
    "        '-y', # (optional) overwrite output file if it exists\n",
    "        '-vcodec', 'rawvideo',\n",
    "        '-f', 'rawvideo',\n",
    "        '-s', get_resolution(frames[0]), # size of one frame\n",
    "        '-pix_fmt', 'rgb24',\n",
    "        '-r', '20', # frames per second\n",
    "        '-i', '-', # The imput comes from a pipe\n",
    "        '-an', # Tells FFMPEG not to expect any audio\n",
    "        '-vcodec', 'mpeg4',\n",
    "        name ]\n",
    "\n",
    "    with sp.Popen( command, stdin=sp.PIPE, stderr=sp.PIPE) as pipe:\n",
    "        for f in frames:\n",
    "            pipe.stdin.write(cv2.cvtColor(f, cv2.COLOR_GRAY2RGB).tostring())\n",
    "    \n",
    "def get_resolution(frame: np.ndarray):\n",
    "    return (\"{}x{}\".format(frame.shape[1], frame.shape[0]))\n",
    "\n",
    "def crop_video(vid: List[np.ndarray], bounds: Bounds):\n",
    "    return [crop_frame(f, bounds) for f in vid]\n",
    "\n",
    "def get_hand(frame: np.ndarray, coords: Coords, shape: Tuple):\n",
    "    minX = max(0, coords.x - shape[1] * 3 // 4)\n",
    "    maxX = min(frame.shape[1], minX + shape[1])\n",
    "    minY = max(0, coords.y - shape[0] * 3 // 4)\n",
    "    maxY = min(frame.shape[0], minY + shape[0])\n",
    "    \n",
    "    if (maxX - minX) != shape[1]:\n",
    "        if maxX == frame.shape[1]:\n",
    "            minX = maxX - shape[1]\n",
    "        else:\n",
    "            maxX = minX + shape[1]\n",
    "    if (maxY - minY) != shape[0]:\n",
    "        if maxY == frame.shape[0]:\n",
    "            minY = maxY - shape[0]\n",
    "        else:\n",
    "            maxY = minY + shape[0]\n",
    "    \n",
    "    return frame[minY:maxY, minX:maxX]\n",
    "\n",
    "def get_left_hand_vid(data: List[np.ndarray], joints: List[Joints], shape: Tuple):\n",
    "    return [get_hand(d[0], d[1].left, shape) for d in zip(data, joints)]\n",
    "\n",
    "def get_right_hand_vid(data: List[np.ndarray], joints: List[Joints], shape: Tuple):\n",
    "    return [get_hand(d[0], d[1].right, shape) for d in zip(data, joints)]\n",
    "\n",
    "def get_higher_hand_vid(left: List[np.ndarray], right: List[np.ndarray], whole: List[np.ndarray],\n",
    "                        joints: List[Joints], labels: List[int]):\n",
    "    current_label = -1\n",
    "    higher_hand = []\n",
    "    main = []\n",
    "    count_left = 0\n",
    "    count_right = 0\n",
    "    hand_left = []\n",
    "    hand_right = []\n",
    "    main_buffer = []\n",
    "    \n",
    "    for p in zip(left, right, whole, joints, labels):\n",
    "        if p[4] != current_label:\n",
    "            if count_left > count_right:\n",
    "                higher_hand += [np.fliplr(f) for f in hand_left]\n",
    "                main += [np.fliplr(f) for f in main_buffer]\n",
    "            else:\n",
    "                higher_hand += hand_right\n",
    "                main += main_buffer\n",
    "            current_label = -1\n",
    "            count_left = 0\n",
    "            count_right = 0\n",
    "            hand_left = []\n",
    "            hand_right = []\n",
    "            main_buffer = []\n",
    "            current_label = p[4]\n",
    "        if p[3].left.y < p[3].right.y:\n",
    "            count_left += 1\n",
    "        else:\n",
    "            count_right += 1\n",
    "        hand_left.append(p[0])\n",
    "        hand_right.append(p[1])\n",
    "        main_buffer.append(p[2])\n",
    "        \n",
    "    if count_left > count_right:\n",
    "        higher_hand += [np.fliplr(f) for f in hand_left]\n",
    "        main += [np.fliplr(f) for f in main_buffer]\n",
    "    else:\n",
    "        higher_hand += hand_right\n",
    "        main += main_buffer\n",
    "        \n",
    "    return higher_hand, main\n",
    "\n",
    "def remove_background(vid, user_vid):\n",
    "    modified_vid = []\n",
    "    for i in range(len(vid)):\n",
    "        modified_vid.append(np.ma.masked_array(vid[i], mask=user_vid[i] == 0, filled_value=124).filled(255))\n",
    "        \n",
    "    return modified_vid\n",
    "\n",
    "def resize_video(vid, shape):\n",
    "    return [cv2.resize(f, shape) for f in vid]\n",
    "\n",
    "def get_uber_video(data: List[DataPoint], shape: Tuple):\n",
    "    #warnings.simplefilter(\"error\")\n",
    "    depth_vid = [d.depth for d in data]\n",
    "    gray_vid = [d.gray for d in data]\n",
    "    user_vid = [d.user for d in data]\n",
    "    joints_list = [d.skel for d in data]\n",
    "    labels_list = [d.label for d in data]\n",
    "    bounds = get_hand_bounds(data)\n",
    "    \n",
    "    cropped_gray_vid = crop_video(gray_vid, bounds)\n",
    "    modified_depth_vid = remove_background(depth_vid, user_vid)\n",
    "    cropped_depth_vid = crop_video(modified_depth_vid, bounds)\n",
    "    cropped_user_vid = crop_video(user_vid, bounds)\n",
    "    \n",
    "    left_gray_vid = get_left_hand_vid(gray_vid, joints_list, shape)\n",
    "    right_gray_vid = get_right_hand_vid(gray_vid, joints_list, shape)\n",
    "    left_depth_vid = get_left_hand_vid(depth_vid, joints_list, shape)\n",
    "    right_depth_vid = get_right_hand_vid(depth_vid, joints_list, shape)\n",
    "    smaller_gray_vid = resize_video(cropped_gray_vid, shape)\n",
    "    smaller_depth_vid = resize_video(cropped_depth_vid, shape)\n",
    "    higher_gray_vid, smaller_gray_vid = get_higher_hand_vid(left_gray_vid, right_gray_vid, smaller_gray_vid, joints_list, labels_list)\n",
    "    higher_depth_vid, smaller_depth_vid = get_higher_hand_vid(left_depth_vid, right_depth_vid, smaller_depth_vid, joints_list, labels_list)\n",
    "    \n",
    "    \n",
    "    uber_vid = []\n",
    "    for i in range(len(depth_vid)):\n",
    "        #uber_frame = np.zeros((shape[0] * 3, shape[1] * 2), dtype='uint8')\n",
    "        uber_frame = np.zeros((shape[0] * 2, shape[1] * 2), dtype='uint8')\n",
    "        #uber_frame[:shape[0],:shape[1]] = left_gray_vid[i]\n",
    "        #uber_frame[:shape[0],shape[1]:2*shape[1]] = right_gray_vid[i]\n",
    "        #uber_frame[shape[0]:2*shape[0],:shape[1]] = left_depth_vid[i]\n",
    "        #uber_frame[shape[0]:2*shape[0],shape[1]:2*shape[1]] = right_depth_vid[i]\n",
    "        #uber_frame[2*shape[0]:3*shape[0],:shape[1]] = smaller_gray_vid[i]\n",
    "        #uber_frame[2*shape[0]:3*shape[1],shape[1]:2*shape[1]] = smaller_depth_vid[i]\n",
    "        uber_frame[:shape[0],:shape[1]] = higher_gray_vid[i]\n",
    "        uber_frame[:shape[0],shape[1]:2*shape[1]] = higher_depth_vid[i]\n",
    "        uber_frame[shape[0]:2*shape[0],:shape[1]] = smaller_gray_vid[i]\n",
    "        uber_frame[shape[0]:2*shape[1],shape[1]:2*shape[1]] = smaller_depth_vid[i]\n",
    "        uber_vid.append(uber_frame)\n",
    "    \n",
    "    return uber_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = read_sample(35)\n",
    "left = get_left_hand_vid([d.gray for d in data], [d.skel for d in data], (64, 64))\n",
    "right = get_right_hand_vid([d.gray for d in data], [d.skel for d in data], (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,f in enumerate(left):\n",
    "    if f.shape != (64, 64):\n",
    "        print(i, f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modified = remove_background([d.gray for d in data], [d.user for d in data])\n",
    "write_video(modified, \"/home/amey/tmp/mod.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left = get_left_hand_vid(data)\n",
    "write_video(left, \"/home/amey/tmp/left.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uber_vid = get_uber_video(data, (64, 64))\n",
    "write_video(uber_vid, \"/home/amey/tmp/uber.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 417\n",
      "Wrote 418\n",
      "Wrote 419\n",
      "Wrote 420\n",
      "Wrote 421\n",
      "Wrote 422\n",
      "Wrote 423\n",
      "Wrote 424\n",
      "Wrote 425\n",
      "Wrote 426\n",
      "Wrote 427\n",
      "Wrote 428\n",
      "Wrote 429\n",
      "Wrote 430\n",
      "Wrote 431\n",
      "Wrote 432\n",
      "Wrote 433\n",
      "Wrote 434\n",
      "Wrote 435\n",
      "Wrote 436\n",
      "Wrote 437\n",
      "Wrote 438\n",
      "Wrote 439\n",
      "Wrote 440\n",
      "Wrote 441\n",
      "Wrote 442\n",
      "Wrote 443\n",
      "Wrote 444\n",
      "Wrote 445\n",
      "Wrote 446\n",
      "Wrote 447\n",
      "Wrote 448\n",
      "Wrote 449\n",
      "Wrote 450\n",
      "Wrote 451\n",
      "Wrote 452\n",
      "Wrote 453\n",
      "Wrote 454\n",
      "Wrote 455\n",
      "Wrote 456\n",
      "Wrote 457\n",
      "Wrote 458\n",
      "Wrote 459\n",
      "Wrote 460\n",
      "Wrote 461\n",
      "Wrote 462\n",
      "Wrote 463\n",
      "Wrote 464\n",
      "Wrote 465\n",
      "Wrote 466\n",
      "Wrote 467\n",
      "Wrote 468\n",
      "Wrote 469\n",
      "Wrote 470\n"
     ]
    }
   ],
   "source": [
    "base = \"/media/amey/76D076A5D0766B6F/chalap/train\"\n",
    "for i in range(417,471):\n",
    "    data = read_sample(i)\n",
    "    uber = get_uber_video(data, (64, 64))\n",
    "    write_video(uber, \"{}/uber/Sample{:04d}.mp4\".format(base, i))\n",
    "    with open(\"{}/uber/Sample{:04d}.pkl\".format(base, i), 'wb') as f:\n",
    "        pickle.dump([d.label for d in data], f)\n",
    "    print(\"Wrote {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "def foveateFrame(frame, focusLoc, focusSize):\n",
    "    print(focusLoc)\n",
    "    height = frame.shape[0] # Get the dimensions\n",
    "    width = frame.shape[1]\n",
    "\n",
    "    # Define mask\n",
    "    mask = 255*np.ones(frame.shape, dtype='uint8')\n",
    "\n",
    "    # Draw circle at x = 100, y = 70 of radius 25 and fill this in with 0\n",
    "    cv2.circle(mask, focusLoc, focusSize, 0, -1)    \n",
    "\n",
    "    # Apply distance transform to mask\n",
    "    out = cv2.distanceTransform(mask, cv2.DIST_L2, 3)\n",
    "\n",
    "    # Define scale factor\n",
    "    scale_factor = 10\n",
    "\n",
    "    # Create output image that is the same as the original\n",
    "    filtered = frame.copy() \n",
    "\n",
    "    # Create floating point copy for precision\n",
    "    frame_float = frame.copy().astype('float')\n",
    "    \n",
    "    # Temp\n",
    "    mask = np.ceil(out / scale_factor)\n",
    "\n",
    "    # For each pixel in the input...\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            # If distance transform is 0, skip\n",
    "            if out[y,x] == 0.0:\n",
    "                continue\n",
    "\n",
    "            # Calculate M = d / S\n",
    "            #mask_val = np.ceil(out[y,x] / scale_factor)\n",
    "            mask_val = out[y,x]\n",
    "\n",
    "            # If M is too small, set the mask size to the smallest possible value\n",
    "            if mask_val <= 3:\n",
    "                mask_val = 3\n",
    "\n",
    "            # Get beginning and ending x and y coordinates for neighbourhood\n",
    "            # and ensure they are within bounds\n",
    "            beginx = x-int(mask_val/2)\n",
    "            if beginx < 0:\n",
    "                beginx = 0\n",
    "\n",
    "            beginy = y-int(mask_val/2)\n",
    "            if beginy < 0:\n",
    "                beginy = 0\n",
    "\n",
    "            endx = x+int(mask_val/2)\n",
    "            if endx >= width:\n",
    "                endx = width-1\n",
    "\n",
    "            endy = y+int(mask_val/2)\n",
    "            if endy >= height:\n",
    "                endy = height-1\n",
    "\n",
    "            # Get the coordinates of where we need to grab pixels\n",
    "            xvals = np.arange(beginx, endx+1)\n",
    "            yvals = np.arange(beginy, endy+1)\n",
    "            (col_neigh,row_neigh) = np.meshgrid(xvals, yvals)\n",
    "            col_neigh = col_neigh.astype('int')\n",
    "            row_neigh = row_neigh.astype('int')\n",
    "\n",
    "            pix = frame[row_neigh, col_neigh].ravel()\n",
    "\n",
    "            # Calculate the average and set it to be the output\n",
    "            filtered[y,x] = int(np.mean(pix))\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 347)\n",
      "(244, 249)\n",
      "(295, 74)\n",
      "295 74 20\n"
     ]
    }
   ],
   "source": [
    "h,l,r = processFrame(data[1], skel[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "name": "opencv.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
