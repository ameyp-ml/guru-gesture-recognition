{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from train_rnn_last import get_batches\n",
    "from layers import layer, conv2d, layer2d, pool, pool_frames, lstm_last, flatten, flatten_multi, dense, dense_multi, weights, bias, get_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from tensorflow.contrib.slim.nets import resnet_v2, resnet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers.python.layers import batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def res_layer(inp, num_features1, stride):\n",
    "    num_features2 = num_features1 * 4\n",
    "    shape = inp.get_shape()\n",
    "    [seq_len, inp_width, num_channels] = [int(shape[i]) for i in [1, 2, 4]]\n",
    "    #[_, seq_len, inp_width, _, num_channels] = [int(i) for i in list(inp.get_shape())]\n",
    "\n",
    "    inputs = tf.reshape(inp, [-1, inp_width, inp_width, num_channels])\n",
    "    \n",
    "    if num_channels == num_features2:\n",
    "        o_l = inputs\n",
    "    else:\n",
    "        b_l = bias(num_features2, 0.2)\n",
    "        w_l = weights([1, 1, num_channels, num_features2], 0.04)\n",
    "        o_l = conv2d(inputs, b_l, w_l, stride)\n",
    "\n",
    "    b1_r = bias(num_features1, 0.2)\n",
    "    w1_r = weights([1, 1, num_channels, num_features1], 0.04)\n",
    "    conv1_r = tf.nn.relu(batch_norm(conv2d(inputs, b1_r, w1_r, stride)))\n",
    "\n",
    "    b2_r = bias(num_features1, 0.2)\n",
    "    w2_r = weights([3, 3, num_features1, num_features1], 0.04)\n",
    "    conv2_r = tf.nn.relu(batch_norm(conv2d(conv1_r, b2_r, w2_r, 1)))\n",
    "\n",
    "    b3_r = bias(num_features2, 0.2)\n",
    "    w3_r = weights([1, 1, num_features1, num_features2], 0.04)\n",
    "    conv3_r = conv2d(conv2_r, b3_r, w3_r, 1)\n",
    "\n",
    "    out = tf.nn.relu(batch_norm(tf.add(o_l, conv3_r)))\n",
    "\n",
    "    shape = out.get_shape()\n",
    "    [out_width, out_features] = [int(shape[i]) for i in [1, 3]]\n",
    "    #[_, out_width, _, out_features] = [int(i) for i in list(out.get_shape())]\n",
    "\n",
    "    return tf.reshape(out, [-1, seq_len, out_width, out_width, out_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq_len = 32\n",
    "batch_size = 5\n",
    "\n",
    "x_h = tf.placeholder(tf.float32, shape=[None, seq_len, 64, 64, 2])\n",
    "x_m = tf.placeholder(tf.float32, shape=[None, seq_len, 64, 64, 2])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 20])\n",
    "\n",
    "# Convolutional layers, hand\n",
    "b_conv1_h, w_conv1_h, h_conv1_h, o_conv1_h = layer(x_h, 16, [5, 5])\n",
    "o_res1_h = res_layer(o_conv1_h, 16, 1)\n",
    "o_res2_h = res_layer(o_res1_h, 16, 1)\n",
    "o_res3_h = res_layer(o_res2_h, 32, 2)\n",
    "o_res4_h = res_layer(o_res3_h, 32, 1)\n",
    "o_res5_h = res_layer(o_res4_h, 32, 1)\n",
    "o_res6_h = res_layer(o_res5_h, 64, 2)\n",
    "o_res7_h = res_layer(o_res6_h, 64, 1)\n",
    "o_res8_h = res_layer(o_res7_h, 64, 1)\n",
    "_, _, _, o_h = layer(o_res8_h, 1, [1,1])\n",
    "#flat_h = flatten(tf.squeeze(o_h))\n",
    "\n",
    "flat_h = flatten_multi(o_h)\n",
    "#b_fc1_h, w_fc1_h, h_fc1_h = dense_multi(flat_h, int(flat_h.get_shape()[2]), 256, 0.1, 0.02)\n",
    "\n",
    "# Convolutional layers, main\n",
    "b_conv1_m, w_conv1_m, h_conv1_m, o_conv1_m = layer(x_m, 16, [5, 5])\n",
    "o_res1_m = res_layer(o_conv1_m, 16, 1)\n",
    "o_res2_m = res_layer(o_res1_m, 16, 1)\n",
    "o_res3_m = res_layer(o_res2_m, 32, 2)\n",
    "o_res4_m = res_layer(o_res3_m, 32, 1)\n",
    "o_res5_m = res_layer(o_res4_m, 32, 1)\n",
    "o_res6_m = res_layer(o_res5_m, 64, 2)\n",
    "o_res7_m = res_layer(o_res6_m, 64, 1)\n",
    "o_res8_m = res_layer(o_res7_m, 64, 1)\n",
    "_, _, _, o_m = layer(o_res8_m, 1, [1,1])\n",
    "#flat_m = flatten(tf.squeeze(o_m))\n",
    "\n",
    "flat_m = flatten_multi(o_m)\n",
    "#b_fc1_m, w_fc1_m, h_fc1_m = dense_multi(flat_m, int(flat_m.get_shape()[2]), 256, 0.1, 0.02)\n",
    "\n",
    "#combined = tf.concat(1, [flat_h, flat_m])\n",
    "combined = tf.concat(2, [flat_h, flat_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output = combined\n",
    "\n",
    "flat = lstm_last(combined, 512 * 2, 2, batch_size, \"lstm\")\n",
    "b_output = bias(20, 0.1)\n",
    "w_output = weights([1024, 20], 0.02)\n",
    "output = tf.matmul(flat, w_output) + b_output\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output, y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CHALAP = \"/media/amey/76D076A5D0766B6F/chalap\"\n",
    "MODEL = \"3d-resnet-bn2\"\n",
    "\n",
    "# Create variables\n",
    "step = 0\n",
    "sess = tf.InteractiveSession()\n",
    "summary_writer = tf.train.SummaryWriter(\"{}/summaries/{}\".format(CHALAP, MODEL), sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "accuracy_summary = tf.placeholder(tf.float32, [])\n",
    "\n",
    "# Initialize/restore\n",
    "sess.run(tf.initialize_all_variables())\n",
    "#saver.restore(sess, \"{}/checkpoints/{}/checkpoint-19\".format(CHALAP, MODEL))\n",
    "\n",
    "# Create summary tensors\n",
    "accuracy_summary_op = tf.scalar_summary(\"train_accuracy\", accuracy_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    acc = []\n",
    "    batches = get_batches(batch_size, seq_len, 1, 400)\n",
    "    for i,batch in enumerate(batches):\n",
    "        step += 1\n",
    "        train_accuracy, _ = sess.run([accuracy, train_step], feed_dict={x_h:batch[0], x_m:batch[1], y: batch[2]})\n",
    "        acc.append(train_accuracy)\n",
    "        if i%100 == 0:\n",
    "            cumulative = sum(acc) / len(acc)\n",
    "            print(\"step %d, training accuracy %g\"%(i, cumulative))\n",
    "            summary_writer.add_summary(accuracy_summary_op.eval(feed_dict={accuracy_summary: cumulative}), step)\n",
    "\n",
    "    saver.save(sess, \"{}/checkpoints/{}\".format(CHALAP, MODEL), global_step=epoch)\n",
    "    \n",
    "    val_batches = get_batches(batch_size, seq_len, 401, 470)\n",
    "    val_cumulative = 0\n",
    "    val_acc = []\n",
    "    for j,batch in enumerate(val_batches):\n",
    "        val_accuracy = sess.run(accuracy, feed_dict={x_h:batch[0], x_m:batch[1], y: batch[2]})\n",
    "        val_acc.append(val_accuracy)\n",
    "        \n",
    "    print(\"Done with epoch: %d, validation accuracy %g\" % (epoch, sum(val_acc) / len(val_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
